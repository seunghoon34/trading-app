
services:
  # PostgreSQL Database
  postgres:
    image: postgres:15
    container_name: trading-postgres
    environment:
      POSTGRES_USER: ${DB_USER}
      POSTGRES_PASSWORD: ${DB_PASSWORD}
      POSTGRES_DB: ${DB_NAME}
    ports:
      - "5432:5432"
    volumes:
      - postgres_data:/var/lib/postgresql/data
    networks:
      - trading-network

  # User Management Service
  user-management:
    build:
      context: ./services/user-management
      dockerfile: Dockerfile
    container_name: user-management-service
    environment:
      - DB_HOST=postgres
      - DB_PORT=5432
      - DB_USER=${DB_USER}
      - DB_PASSWORD=${DB_PASSWORD}
      - DB_NAME=${DB_NAME}
      - JWT_SECRET=${JWT_SECRET}
    ports:
      - "8080:8080"
    depends_on:
      - postgres
    networks:
      - trading-network
  
  # Trading Market Data Service
  market-data:
    build:
      context: ./services/market-data
      dockerfile: Dockerfile
    container_name: market-data-service
    environment:
      - ALPACA_API_KEY=${ALPACA_API_KEY}
      - ALPACA_SECRET_KEY=${ALPACA_SECRET_KEY}
      - ALPACA_MARKET_DATA_URL=${ALPACA_MARKET_DATA_URL}
    ports:
      - "8082:8082"
    networks:
      - trading-network
  # Trading Engine Service
  trading-engine:
    build:
      context: ./services/trading-engine
      dockerfile: Dockerfile
    container_name: trading-engine-service
    environment:
      - ALPACA_API_KEY=${ALPACA_API_KEY}
      - ALPACA_SECRET_KEY=${ALPACA_SECRET_KEY}
    ports:
      - "8083:8083"
    networks:
      - trading-network
  # Portfolio Service
  portfolio:
    build:
      context: ./services/portfolio
      dockerfile: Dockerfile
    container_name: portfolio-service
    environment:
      - ALPACA_API_KEY=${ALPACA_API_KEY}
      - ALPACA_SECRET_KEY=${ALPACA_SECRET_KEY}
    ports:
      - "8084:8084"
    networks:
      - trading-network
    labels:
      - "service.name=trading-engine"
  payment:
    build:
      context: ./services/payment
      dockerfile: Dockerfile
    container_name: payment-service
    environment:
      - ALPACA_API_KEY=${ALPACA_API_KEY}
      - ALPACA_SECRET_KEY=${ALPACA_SECRET_KEY}
    ports:
      - "8088:8088"
    networks:
      - trading-network

  # Event Listener Service
  event-listener:
    build: ./services/event-listener
    container_name: event-listener
    depends_on:
      kafka:
        condition: service_healthy
    ports:
      - "8085:8085"
    environment:
      - ALPACA_API_KEY=${ALPACA_API_KEY}
      - ALPACA_SECRET_KEY=${ALPACA_SECRET_KEY}
      - ALPACA_ACCOUNT_ID=${ALPACA_API_KEY}
    networks:
      - trading-network

  mongodb:
    image: mongo:7.0
    container_name: trading-mongodb
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGO_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGO_PASSWORD}
      MONGO_INITDB_DATABASE: ${MONGO_DATABASE}
    ports:
      - "27017:27017"
    volumes:
      - mongodb_data:/data/db
    networks:
      - trading-network
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.runCommand('ping').ok"]
      interval: 30s
      timeout: 10s
      retries: 5

  # Notification Service
  notification-service:
    build:
      context: ./services/notification
      dockerfile: Dockerfile
    container_name: notification-service
    depends_on:
      kafka:
        condition: service_healthy
      mongodb:
        condition: service_healthy
    ports:
      - "8087:8087"
    environment:
      - MONGODB_URI=mongodb://${MONGO_USER}:${MONGO_PASSWORD}@mongodb:27017
      - MONGODB_DATABASE=${MONGO_DATABASE}
    networks:
      - trading-network 
    
  crewai-portfolio:
    build: ./services/crewai-portfolio
    container_name: crewai-portfolio
    ports:
      - "8000:8000"
    environment:
      - PYTHONUNBUFFERED=1
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - OPENAI_MODEL_NAME=${OPENAI_MODEL_NAME}
      - SERPER_API_KEY=${SERPER_API_KEY}
      - ANTHROPIC_API_KEY=${ANTHROPIC_API_KEY}
    networks:
      - trading-network
  # API Gateway ServiceÃ¥
  api-gateway:
    build:
      context: ./services/api-gateway
      dockerfile: Dockerfile
    container_name: api-gateway-service
    ports:
      - "3000:3000"
    depends_on:
      - user-management
      - market-data
      - trading-engine
      - portfolio
    environment:
      - JWT_SECRET=${JWT_SECRET}
    networks:
      - trading-network
  mongo-express:
    image: mongo-express:latest
    container_name: mongo-express
    depends_on:
      - mongodb
    ports:
      - "8088:8081"
    environment:
      ME_CONFIG_MONGODB_ADMINUSERNAME: ${MONGO_USER}
      ME_CONFIG_MONGODB_ADMINPASSWORD: ${MONGO_PASSWORD}
      ME_CONFIG_MONGODB_URL: mongodb://${MONGO_USER}:${MONGO_PASSWORD}@mongodb:27017/
      ME_CONFIG_BASICAUTH: false
    networks:
      - trading-network
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093,PLAINTEXT_INTERNAL://0.0.0.0:29092
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:29092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT,PLAINTEXT_INTERNAL:PLAINTEXT
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT_INTERNAL
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qg'
    networks:
      - trading-network
    healthcheck:
      test: ["CMD-SHELL", "kafka-topics --bootstrap-server localhost:9092 --list"]
      interval: 30s
      timeout: 10s
      retries: 5
  kafka-init:
    image: confluentinc/cp-kafka:7.4.0
    container_name: kafka-init
    depends_on:
      kafka:
        condition: service_healthy
    command: >
      bash -c "
      echo 'Waiting for Kafka to be ready...'
      sleep 10
      
      echo 'Creating trading platform topics...'
      
      kafka-topics --create --if-not-exists --topic trade-events --bootstrap-server kafka:29092 --partitions 3 --replication-factor 1
      
      kafka-topics --create --if-not-exists --topic market-data --bootstrap-server kafka:29092 --partitions 3 --replication-factor 1
      
      kafka-topics --create --if-not-exists --topic user-events --bootstrap-server kafka:29092 --partitions 3 --replication-factor 1
      
      echo 'Topics created successfully!'
      kafka-topics --list --bootstrap-server kafka:29092
      "
    networks:
      - trading-network
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    depends_on:
      - kafka
    ports:
      - "8086:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: trading-platform
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:29092
    networks:
      - trading-network 
  # Redis Cache Service
  redis:
    image: redis:7-alpine
    ports:
      - "6379:6379"
    volumes:
      - redis_data:/data 
  
  # # ELK Stack Services
  # elasticsearch:
  #   image: docker.elastic.co/elasticsearch/elasticsearch:8.11.0
  #   container_name: elasticsearch
  #   environment:
  #     - discovery.type=single-node
  #     - xpack.security.enabled=false
  #     - "ES_JAVA_OPTS=-Xms512m -Xmx512m"
  #   ports:
  #     - "9200:9200"
  #   volumes:
  #     - elasticsearch_data:/usr/share/elasticsearch/data
  #   networks:
  #     - trading-network
  #   healthcheck:
  #     test: ["CMD-SHELL", "curl -f http://localhost:9200/_cluster/health || exit 1"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5

  # logstash:
  #   image: docker.elastic.co/logstash/logstash:8.11.0
  #   container_name: logstash
  #   ports:
  #     - "5044:5044"
  #     - "9600:9600"
  #   volumes:
  #     - ./infrastructure/logstash/pipeline:/usr/share/logstash/pipeline
  #     - ./infrastructure/logstash/config:/usr/share/logstash/config
  #     # - ./infrastructure/logstash/config:/usr/share/logstash/data # For persistent data
  #   networks:
  #     - trading-network
  #   depends_on:
  #     elasticsearch:
  #       condition: service_healthy
  #   healthcheck:
  #     test: ["CMD-SHELL", "curl -f http://localhost:9600 || exit 1"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5

  # kibana:
  #   image: docker.elastic.co/kibana/kibana:8.11.0
  #   container_name: kibana
  #   ports:
  #     - "5601:5601"
  #   environment:
  #     - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
  #   networks:
  #     - trading-network
  #   depends_on:
  #     elasticsearch:
  #       condition: service_healthy
  #   healthcheck:
  #     test: ["CMD-SHELL", "curl -f http://localhost:5601/api/status || exit 1"]
  #     interval: 30s
  #     timeout: 10s
  #     retries: 5

  # filebeat:
  #   image: docker.elastic.co/beats/filebeat:8.11.0
  #   container_name: filebeat
  #   user: root
  #   volumes:
  #     - ./infrastructure/filebeat/filebeat.yml:/usr/share/filebeat/filebeat.yml:ro
  #     - /var/lib/docker/containers:/var/lib/docker/containers:ro
  #     - /var/run/docker.sock:/var/run/docker.sock:ro
  #   networks:
  #     - trading-network
  #   depends_on:
  #     logstash:
  #       condition: service_healthy
  #   command: filebeat -e -strict.perms=false

# Define network for service communication
networks:
  trading-network:
    driver: bridge

# Define volumes for data persistence
volumes:
  postgres_data:
    driver: local
  mongodb_data:         
    driver: local
  elasticsearch_data:
    driver: local
  redis_data:
    driver: local
